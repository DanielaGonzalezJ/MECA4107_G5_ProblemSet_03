#Test
test <- test %>%
mutate(area= str_extract(description, "(\\d+) mts|(\\d+) mt2|(\\d+) metros|(\\d+) m2|(\\d+) m^2"))
#Extraemos la variable numérica y seleccionamos el area por percentiles
test <- test %>%
mutate(area = as.integer(str_extract(area, "\\d+")))  %>%
mutate(area = ifelse(is.na(area)==F,area, pmin(surface_total, surface_covered, na.rm = TRUE)))
low <- quantile(test$area, 0.05,na.rm=T)
up <- quantile(test$area, 0.90,na.rm=T)
test<- test %>% mutate(area=  ifelse(test=( area>= up),
yes= NA,
no= area ))%>%
mutate(area=  ifelse(test=(area<= low),
yes= NA,
no= area ))
############################################################
################ Imputamos area #########################
#Imputamos dadas caracaterísticas de otros aptos similares
impute_area <- function(df) {
df %>%
group_by(bathrooms, ESTRATO, bedrooms,rooms) %>%
mutate(area = ifelse(is.na(area), mean(area, na.rm = TRUE), area)) %>%
ungroup()}
impute_area_2 <- function(df) {
df %>%
group_by(ESTRATO) %>%
mutate(area = ifelse(is.na(area), mean(area, na.rm = TRUE), area)) %>%
ungroup()
}
train <- impute_area(train)
test <- impute_area(test)
train <- impute_area_2(train)
test <- impute_area_2(test)
summary(train)
summary(test)
############################################################
################ Codigo UPZ #########################
train$codigo_upz[is.na(train$codigo_upz)] <- 0
test$codigo_upz[is.na(test$codigo_upz)] <- 0
# Eliminamos Variables innecesarias
train<- train %>%
select(-operation_type,-surface_total,-surface_covered,-OBJECTID,-CODIGO_ZON,-CODIGO_CRI,-NORMATIVA,-ACTO_ADMIN,NUMERO_ACT,-FECHA_ACTO,-ESCALA_CAP,-FECHA_CAPT,-RESPONSABL,-SHAPE_AREA,-SHAPE_LEN,-objectid,-barrio,-origen_ilegal,-escala_captura,-fecha_captura,-codigo_barrio_h,-formacion,-actualizacion,-codigo_zona,-responsable,-globalid,-shape_area,shape_len,-geo_point_2d,-NUMERO_ACT,-CODIGO_MAN,-shape_len)
test<- test %>%
select(-operation_type,-surface_total,-surface_covered,-OBJECTID,-CODIGO_ZON,-CODIGO_CRI,-NORMATIVA,-ACTO_ADMIN,NUMERO_ACT,-FECHA_ACTO,-ESCALA_CAP,-FECHA_CAPT,-RESPONSABL,-SHAPE_AREA,-SHAPE_LEN,-objectid,-barrio,-origen_ilegal,-escala_captura,-fecha_captura,-codigo_barrio_h,-formacion,-actualizacion,-codigo_zona,-responsable,-globalid,-shape_area,shape_len,-geo_point_2d,-NUMERO_ACT,-CODIGO_MAN,-shape_len)
############################################################
########## Filtrado  de texto: Descripción  ################
############################################################
#Volvemos los comentarios Regresores
descriptions_tr <- train$description
descriptions_te <- test$description
descriptions_source_tr <- VectorSource(descriptions_tr)
descriptions_source_te <- VectorSource(descriptions_te)
# Make a volatile corpus: coffee_corpus (Asociamos metadata a cada doc)
description_corpus_tr <- VCorpus(descriptions_source_tr, readerControl = list( language = "es"))
description_corpus_te <- VCorpus(descriptions_source_te, readerControl = list( language = "es"))
#Limpieza de texto
# Función para reemplazar números por palabras
reemplazar_numeros <- function(texto) {
palabras <- c("cero", "uno", "dos", "tres", "cuatro", "cinco", "seis", "siete", "ocho", "nueve", "diez")
# Reemplazar números del 0 al 10 por palabras
for (i in 0:10) {
texto <- gsub(sprintf("\\b%d\\b", i), palabras[i + 1], texto)
}
return(texto)
}
eliminar_tildes <- function(texto) {
# Convertir texto a formato ASCII eliminando tildes y caracteres especiales
texto_sin_tildes <- iconv(texto, "UTF-8", "ASCII", sub = "")
return(texto_sin_tildes)
}
reemplazar_car_especiales <- function(texto) {
texto_sin_espe <-str_replace_all(texto, "[^[:alnum:]]", " ")
return(texto_sin_espe)
}
## volver a las palabras a sus raíces
stem_espanol<-  function(texto) {
texto_stem <- stemDocument(texto, language="spanish")
return(texto_stem)
}
# Descargamos la lista de las stopwords en español de dos fuentes diferentes y las combinamos
lista_palabras1 <- stopwords(language = "es", source = "snowball")
lista_palabras2 <- stopwords(language = "es", source = "nltk")
lista_palabras <- union(lista_palabras1, lista_palabras2)
lista_palabras<- union(lista_palabras,  c("vendo", "venta", "vende", "etc", "carrera", "calle", "casa", "apto", "apartamento") )
#Consolidamos las funciones
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace) ## remover espacios en blanco
corpus <- tm_map(corpus, removePunctuation)  ## remover puntuacióm
corpus <- tm_map(corpus, content_transformer(tolower)) # todo minuscula
corpus <- tm_map(corpus, removeWords, c(lista_palabras)) # remover stopwords y otras que se quieran añádir
corpus<-  tm_map(corpus, content_transformer(reemplazar_numeros))  ## incluir funciones que nosotros creamos
corpus<-  tm_map(corpus, content_transformer(eliminar_tildes))  ## incluir funciones que nosotros creamos
corpus<-  tm_map(corpus, content_transformer(reemplazar_car_especiales))  ## incluir funciones que nosotros creamos
corpus<-  tm_map(corpus, content_transformer(stem_espanol))
corpus<-  tm_map(corpus, removeNumbers)  # remover numeros restantes
return(corpus)
}
# apliquemos nuestra función de limpieza:
clean_description_tr <- clean_corpus(description_corpus_tr)
clean_description_te <- clean_corpus(description_corpus_te)
#Creación de la Document matrix term
description_dtm_tr <- DocumentTermMatrix(clean_description_tr)
description_dtm_te <- DocumentTermMatrix(clean_description_te)
inspeccion <- inspect(description_dtm_tr)
description_m_tr <- as.data.frame(as.matrix(removeSparseTerms(description_dtm_tr, 0.9), sparse=TRUE))
description_m_te <- as.data.frame(as.matrix(removeSparseTerms(description_dtm_te, 0.9), sparse=TRUE))
description_m_tr <- description_m_tr %>%
mutate(property_id= train$property_id)
description_m_te <- description_m_te %>%
mutate(property_id= test$property_id)
#Análisis PCA
pcdescriptions_tr <- prcomp(as.matrix(removeSparseTerms(description_dtm_tr, 0.9), sparse=TRUE), scale=TRUE)
pcdescriptions_te <- prcomp(as.matrix(removeSparseTerms(description_dtm_te, 0.9), sparse=TRUE), scale=TRUE)
## podemos obtener la varianza explicada
variance_explained_tr <- pcdescriptions_tr$sdev^2 / sum(pcdescriptions_tr$sdev^2)
variance_explained_te <- pcdescriptions_te$sdev^2 / sum(pcdescriptions_te$sdev^2)
df_tr <- data.frame(component_tr = seq_along(variance_explained_tr),
explained_variance_tr = variance_explained_tr,
cumulative_variance_tr = cumsum(variance_explained_tr))
df_te <- data.frame(component_te = seq_along(variance_explained_te),
explained_variance_te = variance_explained_te,
cumulative_variance_te = cumsum(variance_explained_te))
# Plot explained variance
a<- ggplot(df_tr, aes(x = component_tr, y = explained_variance_tr)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Explained Variance by Principal Component",
x = "Principal Component",
y = "Explained Variance") +
theme_minimal()
b <- ggplot(df_tr, aes(x = component_tr, y = cumulative_variance_tr)) +
geom_line(color = "blue") +
geom_point(color = "blue") +
labs(title = "Cumulative Variance by Principal Component",
x = "Principal Component",
y = "Cumulative Variance") +
theme_minimal()
rm(df_tr)
#Plot
grid.arrange(a, b, ncol = 2)
zdescriptions_tr <- as.data.frame(predict(pcdescriptions_tr)) %>%
mutate(property_id= train$property_id)
zdescriptions_te <- as.data.frame(predict(pcdescriptions_te)) %>%
mutate(property_id= test$property_id)
#####################################################################
#Separamos Test y train
#####################################################################
train <- train[train$es_test == 0, ]
test<- test %>%
mutate(es_test=1)
train<- train %>%
mutate(es_test=0)
train_backup <- train
train <- rbind(train, test)
##########################################################
### Agregamos la variable estrato ########################
#Unificar Estrato por cercanía del inmueble al polígono
mzbarrio <- st_make_valid(mzbarrio)
sf_use_s2(FALSE)
train<- st_join(coordinates_tr, mzbarrio, join=st_nearest_feature)
test <- st_join(coordinates_te, mzbarrio, join=st_nearest_feature)
test<- test %>%
mutate(es_test=1)
train<- train %>%
mutate(es_test=0)
train_backup <- train
train <- rbind(train, test)
#Nuevas Cooredenadas
coordinates_tr <- st_as_sf(train, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
coordinates_te <- st_as_sf(test, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
mzbarrio <- st_make_valid(mzbarrio)
sf_use_s2(FALSE)
train<- st_join(coordinates_tr, mzbarrio, join=st_nearest_feature)
test <- st_join(coordinates_te, mzbarrio, join=st_nearest_feature)
##########################################################
### Agregamos la variable Barrio ########################
#Unificar Bariro por cercanía del inmueble al polígono
names(barrio)[names(barrio) == "nombre"] <- "barrio"
barrio <- st_make_valid(barrio)
sf_use_s2(FALSE)
train<- st_join(train, barrio, join=st_nearest_feature)
test <- st_join(test, barrio, join=st_nearest_feature)
##########################################################
### Agregamos Distamcia al CC más cercano ################
# Extraemos la info de todos los CCs
cc <- opq(bbox = getbb("Bogota Colombia")) %>%
add_osm_feature(key = "shop" , value = "mall")
# Cambiamos el formato para que sea un objeto sf (simple features)
cc_sf <- osmdata_sf(cc)
# De las features del parque nos interesa su geomoetría y donde estan ubicados
cc_geometria <- cc_sf$osm_polygons %>%
dplyr::select(osm_id, name)
# Guardemos los poligonos de los CC
cc_geometria <- st_as_sf(cc_sf$osm_polygons)
# Calculamos el centroide de cada CC para aproximar su ubciacion como un solo punto
cc_centroides <- st_centroid(cc_geometria, byid = T)
cc_centroides <- cc_centroides %>%
mutate(x=st_coordinates(cc_centroides)[, "X"]) %>%
mutate(y=st_coordinates(cc_centroides)[, "Y"])
#Visualización de los CC
leaflet() %>%
addTiles() %>%
addPolygons(data = cc_geometria, col = "red",weight = 10,
opacity = 0.8,popup = cc_geometria$name) %>%
addCircles(lng = cc_centroides$x,
lat = cc_centroides$y,
col = "darkblue", opacity = 0.5,radius =1)
#Rectificación de cooredenadas
cc_centroides_sf <- st_as_sf(cc_centroides, coords = c("x", "y"), crs=4326)
cc_sf_tr<- st_as_sf(train, coords = c("lon", "lat"),  crs = 4326)
cc_sf_te<- st_as_sf(test, coords = c("lon", "lat"),  crs = 4326)
# Calculo de la distancia tr
dist_matrix_tr <- st_distance(x = cc_sf_tr, y = cc_centroides_sf)
dist_min_tr <- apply(dist_matrix_tr, 1, min)
# Calculo de la distancia te
dist_matrix_te <- st_distance(x = cc_sf_te, y = cc_centroides_sf)
dist_min_te <- apply(dist_matrix_te, 1, min)
# Agregamos a Train y Test
train <- train %>% mutate(distancia_cc = dist_min_tr)
test <- test %>% mutate(distancia_cc = dist_min_te)
plot <- ggplot(train, aes(x = distancia_cc)) +
geom_histogram(bins = 50, fill = "darkblue", alpha = 0.4) +
labs(x = "Distancia mínima a un Centro Comercial en metros", y = "Cantidad",
title = "Distribución de la distancia a los Centros Comerciales") +
theme_bw()
ggplotly(plot)
##########################################################
### Agregamos Distamcia al Supermercado más cercano ######
# Extraemos la info de todos los SMs
sm <- opq(bbox = getbb("Bogota Colombia")) %>%
add_osm_feature(key = "shop" , value = "supermarket")
# Cambiamos el formato para que sea un objeto sf (simple features)
sm_sf <- osmdata_sf(sm)
# De las features del parque nos interesa su geomoetría y donde estan ubicados
sm_geometria <- sm_sf$osm_polygons %>%
dplyr::select(osm_id, name)
# Guardemos los poligonos de los parques
sm_geometria <- st_as_sf(sm_sf$osm_polygons)
# Calculamos el centroide de cada parque para aproximar su ubciacion como un solo punto
sm_centroides <- st_centroid(sm_geometria, byid = T)
sm_centroides <- sm_centroides %>%
mutate(x=st_coordinates(sm_centroides)[, "X"]) %>%
mutate(y=st_coordinates(sm_centroides)[, "Y"])
#Visualización de los sm
leaflet() %>%
addTiles() %>%
addPolygons(data = sm_geometria, col = "red",weight = 10,
opacity = 0.8,popup = sm_geometria$name) %>%
addCircles(lng = sm_centroides$x,
lat = sm_centroides$y,
col = "darkblue", opacity = 0.5,radius =1)
#Rectificación de cooredenadas
sm_centroides_sf <- st_as_sf(sm_centroides, coords = c("x", "y"), crs=4326)
sm_sf_tr<- st_as_sf(train, coords = c("lon", "lat"),  crs = 4326)
sm_sf_te<- st_as_sf(test, coords = c("lon", "lat"),  crs = 4326)
# Calculo de la distancia tr
dist_matrix_tr <- st_distance(x = sm_sf_tr, y = sm_centroides_sf)
dist_min_tr <- apply(dist_matrix_tr, 1, min)
# Calculo de la distancia te
dist_matrix_te <- st_distance(x = sm_sf_te, y = sm_centroides_sf)
dist_min_te <- apply(dist_matrix_te, 1, min)
# Agregamos a Train y Test
train <- train %>% mutate(distancia_sm = dist_min_tr)
test <- test %>% mutate(distancia_sm = dist_min_te)
plot <- ggplot(train, aes(x = distancia_sm)) +
geom_histogram(bins = 50, fill = "darkblue", alpha = 0.4) +
labs(x = "Distancia mínima a un Centro Comercial en metros", y = "Cantidad",
title = "Distribución de la distancia a los Centros Comerciales") +
theme_bw()
ggplotly(plot)
##########################################################
################ Outliers         #######################
#Baños
train<- train %>% mutate(bathrooms=  ifelse(test=( bathrooms>= 5),
yes= 5,
no= bathrooms ))%>%
mutate(bathrooms=  ifelse(test=(bathrooms<= 1),
yes= 1,
no= bathrooms ))
test<- test %>% mutate(bathrooms=  ifelse(test=( bathrooms>= 5),
yes= 5,
no= bathrooms ))%>%
mutate(bathrooms=  ifelse(test=(bathrooms==0),
yes= 1,
no= bathrooms ))
impute_banio <- function(df) {
df %>%
group_by(ESTRATO, bedrooms,rooms) %>%
mutate(bathrooms = ifelse(is.na(bathrooms), floor(mean(bathrooms, na.rm = TRUE)), bathrooms)) %>%
ungroup()
}
impute_banio_2 <- function(df) {
df %>%
group_by(ESTRATO) %>%
mutate(bathrooms = ifelse(is.na(bathrooms), floor(mean(bathrooms, na.rm = TRUE)), bathrooms)) %>%
ungroup()
}
train <- impute_banio(train)
View(train)
rm(list = ls())
if(!require(pacman)) install.packages("pacman") ; require(pacman)
p_load( tidyverse, # tidy-data
glmnet, # To implement regularization algorithms.
caret, # creating predictive models
skimr,
knitr,
kableExtra,
leaflet, # Mapas interactivos
visdat, #Visualizaci´pon de missings
osmdata,
tmaptools,
sf,
GADMTools,
stringr,
ggplot2,
plotly,
wordcloud,
tidytext,
SentimentAnalysis,
tm,
udpipe,
syuzhet,
rio,
stopwords,
gridExtra
)
#Seleccionamos el directorio y Cargamos las bases de datos
setwd("C:/Users/USER/OneDrive - Universidad de los andes/Semestre VIII/Big Data/MECA4107_G5_ProblemSet_03_v2")
#setwd("C:/Users/madag/OneDrive - Universidad de los andes/Semestre VIII/Big Data/MECA4107_G5_ProblemSet_03")
#Cargamos las bases de Datos
mzbarrio <- st_read("Data/manzanaestratificacion/ManzanaEstratificacion.shp")
barrio <- st_read("Data/manzanaestratificacion/barrios-bogota.geojson")
test<-read.csv("Data/test.csv")
train<-read.csv("Data/train.csv")
#Unificamos lat y lon en una variable
train$longitud <- train$lon
train$latitud <- train$lat
test$longitud <- test$lon
test$latitud <- test$lat
mzbarrio <- st_transform(mzbarrio, crs = 4326)
barrio <- st_transform(barrio, crs = 4326)
coordinates_tr_vis <- st_as_sf(train, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
coordinates_te_vis <- st_as_sf(test, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
##########################################################
###########Primeras Visualizaciones #####################
#Visualizamos las manzanas con Estrato Social asignado
leaflet() %>%
addTiles() %>%  #capa base
addPolygons(data = mzbarrio$geometry, fillColor = "red",color="black", weight = 1)
#Visualizamos los barrios de BTAo
leaflet() %>%
addTiles() %>%  #capa base
addPolygons(data = barrio$geometry, fillColor = "red",color="black", weight = 1)
#Visualizamos los apartamentos por ubicación
leaflet() %>%
addTiles() %>%  #capa base
addCircles(data=coordinates_tr_vis$geometry, fillColor = "blue",color = "blue",weight = 1)
#Plot de estratos por manzana e inmuebles
colores_estrato <- colorNumeric(palette = "RdYlBu", domain = mzbarrio$ESTRATO)
mzbarrio <- st_transform(mzbarrio, crs = 4326)  # Cambia la proyección a WGS84
# Crear el mapa Leaflet
latitud_central <- mean(train$lat)
longitud_central <- mean(train$lon)
leaflet() %>%
addTiles() %>%  # Capa base
addPolygons(data = mzbarrio, fillColor = "#00BFFF", color = "#00BFFF", weight = 1) %>%
setView(lng = longitud_central, lat = latitud_central, zoom = 9) %>%
addCircles(data = coordinates_tr_vis$geometry, fillColor = "#104E8B", color = "#104E8B", weight = 1)
#############################################################
#Unificamos temporalmente test y train
###########################################################
test<- test %>%
mutate(es_test=1)
train<- train %>%
mutate(es_test=0)
train_backup <- train
train <- rbind(train, test)
#Nuevas Cooredenadas
coordinates_tr <- st_as_sf(train, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
coordinates_te <- st_as_sf(test, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
##########################################################
### Agregamos la variable estrato ########################
#Unificar Estrato por cercanía del inmueble al polígono
mzbarrio <- st_make_valid(mzbarrio)
sf_use_s2(FALSE)
train<- st_join(coordinates_tr, mzbarrio, join=st_nearest_feature)
test <- st_join(coordinates_te, mzbarrio, join=st_nearest_feature)
##########################################################
### Agregamos la variable Barrio ########################
#Unificar Bariro por cercanía del inmueble al polígono
names(barrio)[names(barrio) == "nombre"] <- "barrio"
barrio <- st_make_valid(barrio)
sf_use_s2(FALSE)
train<- st_join(train, barrio, join=st_nearest_feature)
test <- st_join(test, barrio, join=st_nearest_feature)
##########################################################
### Agregamos Distamcia al CC más cercano ################
# Extraemos la info de todos los CCs
cc <- opq(bbox = getbb("Bogota Colombia")) %>%
add_osm_feature(key = "shop" , value = "mall")
# Cambiamos el formato para que sea un objeto sf (simple features)
cc_sf <- osmdata_sf(cc)
cc_sf <- osmdata_sf(cc)
cc <- opq(bbox = getbb("Bogota Colombia")) %>%
add_osm_feature(key = "shop" , value = "mall")
cc_sf <- osmdata_sf(cc)
sm <- opq(bbox = getbb("Bogota Colombia")) %>%
add_osm_feature(key = "shop" , value = "supermarket")
# Cambiamos el formato para que sea un objeto sf (simple features)
sm_sf <- osmdata_sf(sm)
rm(list = ls())
if(!require(pacman)) install.packages("pacman") ; require(pacman)
p_load( tidyverse, # tidy-data
glmnet, # To implement regularization algorithms.
caret, # creating predictive models
skimr,
knitr,
kableExtra,
leaflet, # Mapas interactivos
visdat, #Visualizaci´pon de missings
osmdata,
tmaptools,
sf,
GADMTools,
stringr,
ggplot2,
plotly,
wordcloud,
tidytext,
SentimentAnalysis,
tm,
udpipe,
syuzhet,
rio,
stopwords,
gridExtra
)
#Seleccionamos el directorio y Cargamos las bases de datos
setwd("C:/Users/USER/OneDrive - Universidad de los andes/Semestre VIII/Big Data/MECA4107_G5_ProblemSet_03_v2")
#setwd("C:/Users/madag/OneDrive - Universidad de los andes/Semestre VIII/Big Data/MECA4107_G5_ProblemSet_03")
#Cargamos las bases de Datos
mzbarrio <- st_read("Data/manzanaestratificacion/ManzanaEstratificacion.shp")
barrio <- st_read("Data/manzanaestratificacion/barrios-bogota.geojson")
test<-read.csv("Data/test.csv")
train<-read.csv("Data/train.csv")
#Unificamos lat y lon en una variable
train$longitud <- train$lon
train$latitud <- train$lat
test$longitud <- test$lon
test$latitud <- test$lat
mzbarrio <- st_transform(mzbarrio, crs = 4326)
barrio <- st_transform(barrio, crs = 4326)
coordinates_tr_vis <- st_as_sf(train, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
coordinates_te_vis <- st_as_sf(test, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
##########################################################
###########Primeras Visualizaciones #####################
#Visualizamos las manzanas con Estrato Social asignado
leaflet() %>%
addTiles() %>%  #capa base
addPolygons(data = mzbarrio$geometry, fillColor = "red",color="black", weight = 1)
#Visualizamos los barrios de BTAo
leaflet() %>%
addTiles() %>%  #capa base
addPolygons(data = barrio$geometry, fillColor = "red",color="black", weight = 1)
#Visualizamos los apartamentos por ubicación
leaflet() %>%
addTiles() %>%  #capa base
addCircles(data=coordinates_tr_vis$geometry, fillColor = "blue",color = "blue",weight = 1)
#Plot de estratos por manzana e inmuebles
colores_estrato <- colorNumeric(palette = "RdYlBu", domain = mzbarrio$ESTRATO)
mzbarrio <- st_transform(mzbarrio, crs = 4326)  # Cambia la proyección a WGS84
# Crear el mapa Leaflet
latitud_central <- mean(train$lat)
longitud_central <- mean(train$lon)
leaflet() %>%
addTiles() %>%  # Capa base
addPolygons(data = mzbarrio, fillColor = "#00BFFF", color = "#00BFFF", weight = 1) %>%
setView(lng = longitud_central, lat = latitud_central, zoom = 9) %>%
addCircles(data = coordinates_tr_vis$geometry, fillColor = "#104E8B", color = "#104E8B", weight = 1)
#############################################################
#Unificamos temporalmente test y train
###########################################################
test<- test %>%
mutate(es_test=1)
train<- train %>%
mutate(es_test=0)
train_backup <- train
train <- rbind(train, test)
#Nuevas Cooredenadas
coordinates_tr <- st_as_sf(train, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
coordinates_te <- st_as_sf(test, coords = c("lon", "lat"), crs = st_crs(mzbarrio))
##########################################################
### Agregamos la variable estrato ########################
#Unificar Estrato por cercanía del inmueble al polígono
mzbarrio <- st_make_valid(mzbarrio)
sf_use_s2(FALSE)
train<- st_join(coordinates_tr, mzbarrio, join=st_nearest_feature)
test <- st_join(coordinates_te, mzbarrio, join=st_nearest_feature)
##########################################################
### Agregamos la variable Barrio ########################
#Unificar Bariro por cercanía del inmueble al polígono
names(barrio)[names(barrio) == "nombre"] <- "barrio"
barrio <- st_make_valid(barrio)
sf_use_s2(FALSE)
train<- st_join(train, barrio, join=st_nearest_feature)
test <- st_join(test, barrio, join=st_nearest_feature)
##########################################################
### Agregamos Distamcia al CC más cercano ################
# Extraemos la info de todos los CCs
cc <- opq(bbox = getbb("Bogota Colombia")) %>%
add_osm_feature(key = "shop" , value = "mall")
# Cambiamos el formato para que sea un objeto sf (simple features)
cc_sf <- osmdata_sf(cc)
